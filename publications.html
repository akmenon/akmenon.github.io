<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <link rel="stylesheet" type="text/css" href="style.css"/>
  <script src="scripts.js"></script>

  <meta charset="utf-8">
  <meta name="description" content="Aditya Krishna Menon - Fellow, Australian National University">
  <meta name="author" content="Aditya Menon">  

  <title>Publications of Aditya Krishna Menon</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <header id="header">
    <div class="wrapper header">
      <h1 class="logo">Aditya Krishna Menon</h1>
      <nav>
          <ul>
              <li><a href="index.html#bio_anchor">Bio</a></li>
              <li><a href="index.html#interests_anchor">Research</a></li>
              <li><a href="publications.html">Publications</a></li>
              <li><a href="misc.html">Misc</a></li>
          </ul>
      </nav>
    </div>
  </header>  

  <!-- -->
  <!--   <h2>Publications <a class="toggler" href="#" id="publications_anchor" onclick="hideDiv('publications_div');">[-]</a></h2> -->

  Here is a complete list of publications by year. You can also find me on <a href=https://scholar.google.com.au/citations?user=li4mEfcAAAAJ&hl=en>Google Scholar</a>.
  <br><br>

  Inspired by <a href="http://www.cs.princeton.edu/~chazelle/linernotes.html">Bernard Chazelle's</a> wonderful idea of "liner notes" for his papers, I've included some of my own for a few papers. (These are not peer-, or even coauthor-reviewed.)  

  <!-- <div id="publications_div" style="display:none"> -->
  <div id="publications_div">
  <ul style="padding: 0em; list-style: none;">

  <!-- 
  <li> <strong>TITLE</strong>.
  <br>
  Aditya Krishna Menon AND FRIENDS.
  <br>
  To appear in <em>CONFERENCE (<strong>ABBRV</strong>)</em>, PLACE, YEAR.
  <br>
  [<a href="PDFLINK">pdf</a>]
  <br><br>
  -->

  <h3>Preprints</h3>

  <li> <strong>Robust distillation for worst-class performance</strong>.
  <br>
  Serena Wang, Harikrishna Narasimhan, Yichen Zhou, Sara Hooker, Michal Lukasik, and Aditya Krishna Menon.
  <br>
  Manuscript, 2022.
  <br>
  [<a href="http://arxiv.org/pdf/2206.06479">pdf</a>]
  <br><br>

  <li> <strong>When in doubt, summon the titans: efficient inference with large models</strong>.
  <br>
  Ankit Singh Rawat, Manzil Zaheer, Aditya Krishna Menon, Amr Ahmed, and Sanjiv Kumar.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2110.10305">pdf</a>]
  <br><br>

  <hr>

  <h3>2021</h3>

  <li> <strong>Training over-parameterized models with non-decomposable objectives</strong>.
  <br>
  Harikrishna Narasimhan and Aditya Krishna Menon.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2107.04641">pdf</a>]
  <br><br>

  <li> <strong>Disentangling sampling and labeling bias for learning in large-output spaces</strong>.
  <br>
  Ankit Singh Rawat, Aditya Krishna Menon, Wittawat Jitkrittum, Sadeep Jayasumana, Felix X. Yu, Sashank Reddi, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2021.
  <br>
  [<a href="papers/sampling/disentangling.pdf">pdf</a>]
  <br><br>

  <li> <strong>A statistical perspective on distillation</strong>.
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Seungyeon Kim, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2021.
  <br>
  [<a href="papers/distillation/Bayes_Distillation.pdf">pdf</a>]
  <br><br>

  <li> <strong>RankDistil: knowledge distillation for ranking</strong>.
  <br>
  Sashank Reddi, Rama Kumar Pasumarthi, Aditya Krishna Menon, Ankit Singh Rawat, Felix Yu, Seungyeon Kim, Andreas Veit, and Sanjiv Kumar.
  <br>
  In <em>Artificial Intelligence and Statistics (<strong>AISTATS</strong>)</em>, 2021.
  <br>
  [<a href="http://proceedings.mlr.press/v130/reddi21a/reddi21a.pdf">pdf</a>]
  <br><br>

  <li> <strong>Coping with label shift via distributionally robust optimisation</strong>.
  <br>
  Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=BtZhsSGNRNi">pdf</a>]
  <br><br>  

  <li> <strong>Overparameterisation and worst-case generalisation: friend or foe?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=jphnJNOwe36">pdf</a>]
  <br><br>  

  <li> <strong>Long-tail learning via logit adjustment</strong>.
  <br>
  Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=37nvvqkCo5">pdf</a>]
  <br><br>

  <hr>

  <h3>2020</h3>
  <li> <strong>Robust large-margin Learning in hyperbolic space</strong>.
  <br>
  Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.05465">pdf</a>]
  <br><br>

  <li> <strong>Semantic label smoothing for sequence to sequence problems.</strong>
  <br>
  Michal Lukasik, Himanshu Jain, Aditya Krishna Menon, Seungyeon Kim, Srinadh Bhojanapalli, Felix Yu and Sanjiv Kumar.
  <br>
  In <em>Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/abs/2010.07447">pdf</a>]
  <br><br>

  <li> <strong>SupMMD: a sentence importance model for extractive summarization using maximum mean discrepancy.</strong>
  <br>
  Umanga Bista, Alexander Patrick Mathews, Aditya Krishna Menon, and Lexing Xie.
  <br>
  In <em>Empirical Methods in Natural Language Processing Findings (<strong>EMNLP Findings</strong>)</em>, 2020.
  <br>
  [<a href="papers/sup-mmd/SupMMD.pdf">pdf</a>]
  <br><br>

  <li> <strong>Does label smoothing mitigate label noise?</strong>
  <br>
  Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2003.02819">pdf</a>]
  <br><br>

  <li> <strong>Supervised learning: no loss no cry</strong>.
  <br>
  Richard Nock and Aditya Krishna Menon.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2002.03555">pdf</a>]
  <br><br>
  
  <li> <strong>Federated learning with only positive labels</strong>.
  <br>
  Felix X. Yu, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.10342">pdf</a>]
  <br><br>

  <li> <strong>Can gradient clipping mitigate label noise?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, Addis Ababa 2020.
  <br>
  [<a href="https://openreview.net/pdf?id=rklB76EKPr">pdf</a>]
  <br><br>

  <hr>

  <h3>2019</h3>

  <li> <strong>Noise-tolerant fair classification</strong>.
  <br>
  Alexandre Louis Lamy, Ziyuan Zhong, Aditya Krishna Menon, and Nakul Verma.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Vancouver, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.10837">pdf</a>]
  <br><br>

  <li> <strong>Multilabel reductions: what is my loss optimising?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Vancouver, 2019.
  <br>
  [<a href="papers/multilabel_reductions/multilabel_reductions.pdf">pdf</a>] [<a href="papers/multilabel_reductions/multilabel_slides.pdf">slides</a>] [<a href="papers/multilabel_reductions/multilabel_poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Fairness risk measures</strong>.
  <br>
  Robert C. Williamson and Aditya Krishna Menon.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.08665">pdf</a>]
  <br><br>

  <li> <strong>Complementary-label learning for arbitrary losses and models</strong>.
  <br>
  Takashi Ishida, Gang Niu, Aditya Krishna Menon, and Masashi Sugiyama.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1810.04327">pdf</a>]
  <br><br>

  <li> <strong>Monge blunts Bayes: hardness results for adversarial training</strong>.
  <br>
  Zac Cranko, Aditya Krishna Menon, Richard Nock, Cheng-Soon Ong, Zhan Shi, and Christian Walder.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1806.02977">pdf</a>]
  <br><br>

  <li> <strong>On the minimal supervision for training any binary classifier from only unlabeled data</strong>.
  <br>
  Nan Lu, Gang Niu, Aditya Krishna Menon and Masashi Sugiyama.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, New Orleans, 2019.
  <br>
  [<a href="https://openreview.net/pdf?id=B1xWcj0qYm">pdf</a>]
  <br><br>

  <li> <strong>Comparative document collection via classification</strong>.
  <br>
  Umanga Bista, Alexander Mathews, Minjeong Shin, Aditya Krishna Menon and Lexing Xie.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, Honolulu, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1812.02171v1.pdf">pdf</a>]
  <br><br>

  <li> <strong>The risk of trivial solutions in bipartite top ranking</strong>.
  <br>
  Aditya Krishna Menon.
  <br>
  In <em><strong>Machine Learning</strong></em>, Volume 108, Issue 4, 2019.
  <br>
  [<a href="papers/top-ranking/top-ranking.pdf">pdf</a>]
  <br><br>  

  <hr>

  <h3>2018</h3>

  <li> <strong>A loss framework for calibrated anomaly detection</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Montreal, 2018.
  <br>
  [<a href="papers/proper-anomaly/proper-anomaly.pdf">pdf</a>]
  <br><br>

  <li> <strong>Learning from binary labels with instance-dependent corruption</strong>.
  <br>
  Aditya Krishna Menon, Brendan van Rooyen, and Nagarajan Natarajan.
  <br>    
  In <em><strong>Machine Learning</strong></em>, Volume 107 Issue 8-10 (Special Issue on Papers from <em><strong>ECML-PKDD</strong></em>), 2018.
  <br>
  [<a href="papers/noisetron/noisetron.pdf">pdf</a>]
  <br><br>

  <li> <strong>The cost of fairness in binary classification</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>    
  In <em>Conference on Fairness, Accountability, and Transparency (<strong>FAT</strong>)</em>, New York City, 2018.
  <br>
  [<a href="https://arxiv.org/pdf/1705.09055">pdf</a>]
  <br><br>
  <!-- <br><br> -->  

  <li> <strong>Proper losses for nonlinear Hawkes processes</strong>.
  <br>
  Aditya Krishna Menon and Young Lee.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, New Orleans, 2018.
  <br>
  [<a href="papers/proper_hawkes/proper_hawkes_aaai18.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2017</h3>

  <li> <strong>f-GANs in an information geometric nutshell</strong>.
  <br>
  Richard Nock, Zac Cranko, Aditya Krishna Menon, Lizhen Qu and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NIPS</strong>)</em>, Los Angeles, 2017.
  <br>
  [<a href="papers/vig_gan/vig_gan_nips17.pdf">pdf</a>]
  <br><br>

  <li> <strong>Predicting short-term public transport demand via inhomogeneous Poisson processes</strong>.
  <br>
  Aditya Krishna Menon and Young Lee.
  <br>
  In <em>International Conference on Information and Knowledge Management (<strong>CIKM</strong>)</em>, Singapore, 2017.
  <br>
  [<a href="papers/poisson-regression/poisson_cikm17.pdf">pdf</a>]
  <br><br>

  <li> <strong>Revisiting revisits in trajectory recommendation</strong>.
  <br>
  Aditya Krishna Menon, Dawei Chen, Lexing Xie and Cheng Soon Ong.
  <br>
  In <em>RecSys Workshop on Recommender Systems for Citizens (<strong>CitRec</strong>)</em>, Como, 2017.
  <br>
  [<a href="papers/list_viterbi/list_viterbi.pdf">pdf</a>]
  <br><br>

  <li> <strong>Robust, deep and inductive anomaly detection</strong>.
  <br>
  Raghavendra Chalapathy, Aditya Krishna Menon and Sanjay Chawla.
  <br>
  In <em>European Conference on Machine Learning (<strong>ECML/PKDD</strong>)</em>, Skopje, 2017.
  <br>
  [<a href="papers/robust_ae/robust_ae.pdf">pdf</a>]
  <br><br>

  <li> <strong>Making deep neural networks robust to label noise: a loss correction approach</strong>.
  <br>
  Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, Lizhen Qu.
  <br>
  In <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, Honolulu, 2017.
  <br>
  [<a href="papers/deep-noise/deep-noise-paper.pdf">pdf</a>] [<a href="http://giorgiopatrini.org/assets/slides/2017_CVPR.pdf">slides</a>]
  <br><br>

  <li> <strong>Low-rank linear cold-start recommendation from social data</strong>.
  <br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Lexing Xie, and Darius Braziunas.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, San Francisco, 2017.
  <br>
  [<a href="papers/loco/loco-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2016</h3>
   
  <li> <strong>Bipartite ranking: a risk-theoretic perspective</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Journal of Machine Learning Research (<strong>JMLR</strong>)</em>, Volume 17, Issue 195. 2016.
  <br>
  [<a href="http://jmlr.org/papers/volume17/14-265/14-265.pdf">pdf</a>] [<a href="javascript:;" onclick="showDiv('liner_bipartite');">liner notes</a>]  

          <div id="liner_bipartite" style="display:none">
            <br>
            <p style='color:gray'>
            Back in 2011, months of exhaustive experimentation with AUC maximisation in the context of link prediction taught me one thing: it's hard to do better than logistic regression. I was excited when later that year, <a href=http://www.icml-2011.org/papers/567_icmlpaper.pdf>Kot≈Çowski et al.</a> gave a compelling theoretical explanation for why this might be.
            <br><br>
            When I joined NICTA in 2013, I followed a rite of passage and read Mark Reid and Bob Williamson's <a href=http://www.jmlr.org/papers/v12/reid11a.html>tour de force</a> on information, divergences, and risks. Tucked away in that paper was a mention of how the AUC related to the concepts presented. I innocently mentioned to Bob that perhaps there was more to be said here. He agreed, and suggested that I start by spelling out what was in my mind.
            <br><br>
            We never expected it would take quite that long to spell.
            [<a href="javascript:;" onclick="hideDiv('liner_bipartite');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <strong>A scaled Bregman theorem with applications</strong>.
  <br>
  Richard Nock, Aditya Krishna Menon and Cheng Soon Ong.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NIPS</strong>)</em>, Barcelona, 2016.
  <br>
  [<a href="https://arxiv.org/abs/1607.00360">pdf</a>]

  <br><br>

  <li> <strong>Linking losses for density ratio and class-probability estimation.</strong>
  <br>
  Aditya Krishna Menon and Cheng Soon Ong.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, New York City, 2016.
  <br>
  [<a href="papers/density-ratio/density-ratio-paper.pdf">pdf</a>] [<a href="papers/density-ratio/density-ratio-slides.pdf">slides</a>] [<a href="papers/density-ratio/density-ratio-poster.pdf">poster</a>] [<a href="papers/density-ratio/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_density');">liner notes</a>]  

          <div id="liner_density" style="display:none">
            <br>
            <p style='color:gray'>
            Long before being introduced to proper losses, I'd known about, and completely accepted, the basic premise as to why density ratio was different to class-probability estimation: the later only <em>indirectly</em> modelled the ratio, which is generally a sub-optimal strategy. Sometime in late 2015, I re-read the cool work on <a href=http://www.jmlr.org/papers/volume10/kanamori09a/kanamori09a.pdf>LSIF</a>. This time, with link functions and partial losses fresh in my mind, I noticed that one could think of this as involving a particular proper loss plus link function. This was mildly interesting, but the point remained: using anything but the link that directly yields the density ratio must be a bad idea.
            <br><br>
            This was something of a defeat for my running theory at the time, that most everything can be attacked with some version of logistic regression. To better understand this failure mode, I was looking at Sugiyama's <a href=http://www.ism.ac.jp/editsec/aism/pdf/10463_2011_Article_343.pdf>elegant unified Bregman view</a> of density ratios. I noticed that logistic regression was mentioned, but didn't pay much attention to it; after all, the Bregman view of regret under proper losses immediately led to the KL minimisation view of logistic regression.
            <br><br>
            It was only on a re-read that I realised there was a bit more to this innocuous result: it was a statement of Bregman minimisation not to the true probability, but to the true density ratio. Now that I didn't know was true for logistic regression. Studying the surprisingly simple proof, I saw it could be viewed as a surprising equality between the KL divergence on probabilities and on ratios.
            <br><br>
            I was sure this couldn't be true in general; but why? I worked through the case of a general divergence, trying to find out the line where the proof would break.
            <br><br>
            Half an hour later, after staring at my working multiple times, I was still incredulous that everything seemed to work in general, too. And so was Lemma 2 born. [<a href="javascript:;" onclick="hideDiv('liner_density');">hide</a>]            
            </p>            
          </div>

  <br><br>

  <li> <strong>Practical linear models for large-scale one-class collaborative filtering.</strong><br>
  Suvash Sedhain, Hung Bui, Jaya Kawale, Nikos Vlassis, Branislav Kveton, Aditya Krishna Menon, Trung Bui and Scott Sanner.
  <br>
  In <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, New York City, 2016.
  <br>
  [<a href="papers/lrec-low/lrec-low-paper.pdf">pdf</a>]

  <br><br>

  <li> <strong> On the effectiveness of linear models for one-class collaborative filtering.</strong><br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Darius Braziunas.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, Phoenix, 2016.
  <br>
  [<a href="papers/lrec/lrec-paper.pdf">pdf</a>] [<a href="papers/lrec/lrec-slides.pdf">slides</a>] [<a href="https://github.com/mesuvash/LRec">code</a>]

  <br><br>

  <hr>

  <h3>2015</h3>

  <li> <strong>Learning with symmetric label noise: the importance of being unhinged.</strong><br>
  Brendan van Rooyen, Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Processing Systems (<strong>NIPS</strong>)</em>, Montreal, 2015.
  <br>
  [<a href="papers/unhinged/unhinged-paper.pdf">pdf</a>] [<a href="papers/unhinged/unhinged-poster.pdf">poster</a>]

  <br><br>

  <li> <strong>Fine-grained OD estimation with automated zoning and sparsity regularisation.</strong><br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.
  <br>
  In <em><strong>Transportation Research Part B: Methodological</strong></em>, Volume 80, October 2015, Pages 150-172.
  <br>
  [<a href="papers/od-estimation/od-estimation-journal-paper.pdf">pdf</a>]

  <br><br>

  <li> <strong>Learning from corrupted binary labels via class-probability estimation.</strong><br>
  Aditya Krishna Menon, Brendan van Rooyen, Cheng Soon Ong and Robert C. Williamson.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Lille, 2015.
  <br>
  [<a href="papers/corrupted-labels/corrupted-labels-paper.pdf">pdf</a>] [<a href="papers/corrupted-labels/corrupted-labels-slides.pdf">slides</a>] [<a href="papers/corrupted-labels/corrupted-labels-poster.pdf">poster</a>] [<a href="papers/corrupted-labels/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_corrupt');">liner notes</a>]  

          <div id="liner_corrupt" style="display:none">
            <br>
            <p style='color:gray'>
            Ever since I read Elkan and Noto's <a href=https://dl.acm.org/citation.cfm?id=1401920>2008 paper on PU learning</a>, I was fascinated by the topic and their approach; I also felt like I didn't fully grok either, since their sample-selection bias viewpoint was unfamiliar to me. I was inspired to rectify this deficiency on my part when reading one of <a href=http://proceedings.mlr.press/v45/Christoffel15.pdf>du Plessis and Sugiyama's elegant papers</a> that extended this work, and crisply stated the problem in terms of the distributions the underlying samples are drawn from.
            <br><br>
            Around the same time, I also stumbled upon some beautiful works on label noise, notably those of <a href=http://proceedings.mlr.press/v30/Scott13.html>Scott et al.</a> and <a href=https://papers.nips.cc/paper/5073-learning-with-noisy-labels.pdf>Natarajan et al.</a>
            I was struck by the apparent similarity of the two problems, but still couldn't quite decipher the apparently different approaches taken to solve them.
            <br><br>
            At this stage, I sought to clarify in my mind how precisely these different problems relate. Which, as is my wont, involved thinking about them in terms of class-probabilities. On discussing ideas with colleagues at NICTA (serendipitously interested in very similar problems), soon enough we ended up writing this paper. [<a href="javascript:;" onclick="hideDiv('liner_corrupt');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <strong>AutoRec: autoencoders meet collaborative filtering.</strong><br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Lexing Xie.
  <br>
  In <em>International World Wide Web Conference (<strong>WWW</strong>)</em>, Florence, 2015.
  <br>
  [<a href="papers/autorec/autorec-paper.pdf">pdf</a>] [<a href="https://github.com/mesuvash/NNRec">code</a>] [<a href="papers/autorec/autorec-poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Cross-modal retrieval: a pairwise classification approach.</strong><br>
  Aditya Krishna Menon, Didi Surian and Sanjay Chawla.
  <br>
  In <em>SIAM Conference on Data Mining (<strong>SDM</strong>)</em>, Vancouver, 2015.
  <br>
  [<a href="papers/cross-modal/cross-modal-paper.pdf">pdf (with supplementary)</a>] [<a href="papers/cross-modal/cross-modal-slides.pdf">slides</a>] [<a href="papers/cross-modal/index.html">code</a>]
  <br><br>

  <li> <strong>An approach to sparse, fine-grained OD estimation.</strong><br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.
  <br>
  In <em>94th Annual Meeting of the Transporation Research Board (<strong>TRB</strong>)</em>, Washington DC, 2015.
  <br>
  [<a href="papers/od-estimation/od-estimation-paper.pdf">pdf</a>] [<a href="papers/od-estimation/od-estimation-poster.pdf">poster</a>]
  <br><br>

  <hr>

  <h3>2014</h3>

  <li> <strong>Bayes-optimal scorers for bipartite ranking.</strong><br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Conference on Learning Theory (<strong>COLT</strong>)</em>, Barcelona, 2014.
  <br>
  [<a href="http://jmlr.org/proceedings/papers/v35/menon14.html">pdf</a>] [<a href="papers/bipartite/bipartite-slides.pdf">slides</a>] [<a href="papers/bipartite/bipartite-poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Inappropriate access detection for electronic health records using collaborative filtering.</strong><br>
  Aditya Krishna Menon, Xiaoqian Jiang, Jihoon Kim, Lucila Ohno-Machado, and Jaideep Vaidya.
  <br>
  In <strong><em>Machine Learning</em></strong>, Volume 95 Number 1, Special Issue on Machine Learning for Society</em></strong>, 2014.
  <br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5376-1">pdf</a>]
  <br><br>

  <hr>

  <h3>2013</h3>

  <li> <strong>A colorful approach to text processing by example.</strong><br>
  Kuat Yessenov, Shubham Tulsiani, Aditya Krishna Menon, Robert C. Miller, Sumit Gulwani, Butler Lampson, and Adam Kalai.
  <br>In <em>ACM Symposium on User Interface Software and Technology (<strong>UIST</strong>)</em>, 2013.
  <br>
  [<a href="http://dl.acm.org/citation.cfm?id=2502040">pdf</a>]
  <br><br>

  <li> <strong>Beam search algorithms for multilabel learning.</strong><br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.
  <br>
  In <strong><em>Machine Learning</em></strong>, 2013.
  <br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5371-6">pdf</a>]
  <br><br>

  <li> <strong>On the statistical consistency of algorithms for binary classification under class imbalance.</strong><br>
  Aditya Krishna Menon, Harikrishna Narasimhan, Shivani Agarwal and Sanjay Chawla.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Atlanta, 2013.
  <br>
  [<a href="http://jmlr.org/proceedings/papers/v28/menon13a.pdf">pdf</a>] [<a href="papers/imbalance/imbalance-slides.pdf">slides</a>]
  <br><br>

  <li> <strong>A machine learning framework for programming by example.</strong><br>
  Aditya Krishna Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, and Adam Tauman Kalai.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Atlanta, 2013.
  <br>
  [<a href="http://jmlr.csail.mit.edu/proceedings/papers/v28/menon13.pdf">pdf</a>] [<a href="papers/pbe/pbe-poster.pdf">poster</a>] [<a href="papers/pbe/index.html">data</a>]
  <br><br>

  <hr>

  <h3>2012</h3>

  <li> <strong>Learning and inference in Probabilistic Classifier Chains with beam search.</strong><br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.
  <br>
  In <em>Machine Learning and Knowledge Discovery in Databases - European Conference (<strong>ECML-PKDD</strong>), Proceedings Part I</em>, 2012.
  <br>
  [<a href="http://www.springerlink.com/content/m71407113726156x/">pdf</a>]
  <br><br>

  <li> <strong>Doubly optimized calibrated Support Vector Machine (DOC-SVM): an algorithm for joint optimization of discrimination and calibration.</strong><br>
  Xiaoqian Jiang, Aditya Krishna Menon, Shuang Wang, Jihoon Kim, and Lucila Ohno-Machado.
  <br>
  In <strong><em>PLoS ONE</strong></em>, 7(11): e48823, 2012.
  <br>
  [<a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048823">pdf</a>] 
  <br><br>

  <li> <strong>Predicting accurate probabilities with a ranking loss.</strong><br>
  Aditya Krishna Menon, Xiaoqian Jiang, Shankar Vembu, Charles Elkan, and Lucila Ohno-Machado.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Edinburgh, 2012.
  <br>
  [<a href="http://icml.cc/2012/papers/372.pdf">pdf</a>] [<a href="papers/calibration/calibration-poster.pdf">poster</a>] [<a href="papers/calibration/index.html">code</a>]
  <br><br>

  <hr>

  <h3>2011</h3>

  <li> <strong>Link prediction via matrix factorization.</strong><br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>Machine Learning and Knowledge Discovery In Databases - European Conference,
  <strong>ECML-PKDD</strong>, Proceedings Part II</em>, 2011.
  <br>
  [<a href="http://www.springerlink.com/content/h1041601305807n0">pdf</a>] [<a href="papers/link-prediction/link-prediction-poster.pdf">poster</a>] [<a href="papers/link-prediction/index.html">code</a>]
  <br><br>

  <li> <strong>Response prediction using collaborative filtering with hierarchies and side-information.</strong><br>
  Aditya Krishna Menon, Krishna-Prasad Chitrapura, Sachin Garg, Deepak Agarwal, and Nagaraj Kota.
  <br>
  In <em>Knowledge Discovery and Data Mining (<strong>KDD</strong>)</em>, San Diego, 2011.
  <br>
  [<a href="papers/response-prediction/response-prediction-paper.pdf">pdf</a>] [<a href="papers/response-prediction/response-prediction-slides.pdf">slides</a>] [<a href="papers/response-prediction/response-prediction-poster.pdf">poster</a>] [<a href="papers/response-prediction/code.zip">code</a>]
  <br><br>

  <hr>

  <h3>2010</h3>

  <li> <strong>Fast algorithms for approximating the singular value decomposition.</strong><br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>Transactions of Knowledge and Data Discovery: Special Issue on Large-Scale Data Mining (<strong>TKDD-LDMTA</strong>)</em>, 2010.
  <br>
  [<a href="http://dl.acm.org/citation.cfm?id=1921639">pdf</a>] [<a href="papers/code-fastsvd.zip">code</a>]
  <br><br>

  <li> <strong>A log-linear model with latent features for dyadic prediction.</strong><br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>International Conference on Data Mining (<strong>ICDM</strong>)</em>, Sydney, 2010.
  <br>
  [<a href="papers/lfl/lfl-paper.pdf">pdf</a>] [<a href="papers/lfl/lfl-slides.pdf">slides</a>] [<a href="papers/lfl/index.html">code</a>]
  <br><br>

  <li> <strong>Predicting labels for dyadic data.</strong><br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em><strong>Data Mining and Knowledge Discovery</strong></em>, Special Issue on Papers from <strong><em>ECML-PKDD</em></strong></em> Volume 21, Number 2, 2010.
  <br>
  [<a href="http://www.springerlink.com/content/115p058437104h7k/fulltext.pdf">pdf</a>] [<a href="papers/labels-dyadic/labels-dyadic-slides.pdf">slides</a>]
  <br><br>

  <hr>

  <h3>2007</h3>

  <li> <strong>An incremental data-stream sketch using sparse random projections.</strong><br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.
  <br>
  In <em>SIAM Conference on Data Mining (<strong>SDM</strong>)</em>, Minnesota, 2007.
  <br>
  [<a href="papers/random-projections/random-projections-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>Misc</h3>

  <li> <strong>Teacher's pet: understanding and mitigating biases in distillation</strong>.
  <br>
  Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2106.10494">pdf</a>]
  <br><br>

  <li> <strong>Distilling double descent</strong>.
  <br>
  Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit Singh Rawat, Sashank J. Reddi, and Yichen Zhou.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2102.06849">pdf</a>]
  <br><br>  

  <li> <strong>On the reproducibility of neural network predictions</strong>.
  <br>
  Srinadh Bhojanapalli, Kimberly Wilber, Andreas Veit, Ankit Singh Rawat, Seungyeon Kim, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2102.03349">pdf</a>]
  <br><br>

  <li> <strong>Doubly-stochastic mining for heterogeneous retrieval</strong>.
  <br>
  Ankit Singh Rawat, Aditya Krishna Menon, Andreas Veit, Felix Yu, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  Unpublished manuscript, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.10915">pdf</a>]
  <br><br>

  <li> <strong>Cold-start playlist recommendation with multitask learning</strong>.
  <br>
  Dawei Chen, Cheng Soon Ong, and Aditya Krishna Menon.
  <br>
  Unpublished manuscript, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.06125">pdf</a>]
  <br><br>

  <li> <strong>Structured recommendation</strong>.
  <br>
  Dawei Chen, Lexing Xie, Aditya Krishna Menon, and Cheng Soon Ong.
  <br>
  Unpublished manuscript, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1706.09067">pdf</a>]
  <br><br>

  <li> <strong>Large-scale Support Vector Machines: algorithms and theory.</strong><br>
  Aditya Krishna Menon.
  <br>
  Research Exam, University of California, San Diego. 2009.
  <br>
  [<a
  href="papers/research-exam/research-exam-paper.pdf">pdf</a>] [<a href="papers/research-exam/research-exam-slides.pdf">slides</a>]
  <br><br>

  <li> <strong>An incremental data-stream sketch using sparse random projections.</strong><br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.
  <br>
  Technical Report 609, University of Sydney. 2007.
  <br>
  [<a href="papers/random-projections/random-projections-tr-paper.pdf">pdf</a>]
  <br><br>  

  <li> <strong>Random projections and applications to dimensionality reduction.</strong><br>
  Aditya Krishna Menon.
  <br>
  Honours thesis, University of Sydney. 2006.
  <br>
  [<a href="papers/honours/honours-thesis.pdf">pdf</a>] [<a href="papers/honours/honours-slides.pdf">slides</a>]  

  </ul>

  <hr>

  </div>

</div>

</body>

</html>
