<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <link rel="stylesheet" type="text/css" href="style.css"/>
  <script src="scripts.js"></script>

  <meta charset="utf-8">
  <meta name="description" content="Aditya Krishna Menon - Staff Research Scientist, Google">
  <meta name="author" content="Aditya Menon">  

  <title>Publications of Aditya Krishna Menon</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <header id="header">
    <div class="wrapper header">
      <h1 class="logo">Aditya Krishna Menon</h1>
      <nav>
          <ul>
              <li><a href="index.html#bio_anchor">Bio</a></li>
              <li><a href="index.html#interests_anchor">Research</a></li>
              <li><a href="publications.html">Publications</a></li>
              <li><a href="talks.html">Talks</a></li>
              <li><a href="misc.html">Misc</a></li>
          </ul>
      </nav>
    </div>
  </header>  

  <!-- -->
  <!--   <h2>Publications <a class="toggler" href="#" id="publications_anchor" onclick="hideDiv('publications_div');">[-]</a></h2> -->

  Here is a complete list of publications by year. You can also find me on <a href=https://scholar.google.com.au/citations?user=li4mEfcAAAAJ&hl=en>Google Scholar</a>.
  <br><br>

  Inspired by <a href="http://www.cs.princeton.edu/~chazelle/linernotes.html">Bernard Chazelle's</a> wonderful idea of "liner notes" for his papers, I've included some of my own for a few papers. (These are not peer-, or even coauthor-reviewed.)  

  <!-- <div id="publications_div" style="display:none"> -->
  <div id="publications_div">
  <ul style="padding: 0em; list-style: none;">

  <!-- 
  <li> <strong>TITLE</strong>.
  <br>
  Aditya Krishna Menon AND FRIENDS.
  <br>
  To appear in <em>CONFERENCE (<strong>ABBRV</strong>)</em>, PLACE, YEAR.
  <br>
  [<a href="PDFLINK">pdf</a>]
  <br><br>
  -->

  <h3>Preprints</h3>

  <li> <strong>Bipartite ranking from multiple labels: on loss versus label aggregation.</strong>
  <br>
  Michal Lukasik, Lin Chen, Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, Felix X. Yu, Sashank J. Reddi, Gang Fu, Mohammadhossein Bateni, and Sanjiv Kumar.
  <br>
  Manuscript, 2025.
  <br>
  [<a href="https://arxiv.org/pdf/2504.11284">pdf</a>]
  <br><br>

  <li> <strong>Universal model routing for efficient LLM inference.</strong>
  <br>
  Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Zifeng Wang, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  Manuscript, 2025.
  <br>
  [<a href="https://arxiv.org/pdf/2502.08773">pdf</a>]
  <br><br>

  <li> <strong>A little help goes a long way: efficient LLM training by leveraging small LMs.</strong>
  <br>
  Ankit Singh Rawat, Veeranjaneyulu Sadhanala, Afshin Rostamizadeh, Ayan Chakrabarti, Wittawat Jitkrittum, Vladimir Feinberg, Seungyeon Kim, Hrayr Harutyunyan, Nikunj Saunshi, Zachary Nado, Rakesh Shivanna, Sashank J. Reddi, Aditya Krishna Menon, Rohan Anil, and Sanjiv Kumar.
  <br>
  Manuscript, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2410.18779">pdf</a>]
  <br><br>

  <hr>

  <h3>2025</h3>

  <li> <strong>Faster cascades via speculative decoding</strong>.
  <br>
  Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Seungyeon Kim, Neha Gupta, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025.
  <br>
  [<a href="https://arxiv.org/pdf/2405.19261">pdf</a>]
  <br><br>

  <li> <strong>Better autoregressive regression with LLMs via regression-aware fine-tuning</strong>.
  <br>
  Michal Lukasik, Zhao Meng, Harikrishna Narasimhan, Yin-Wen Chang, Aditya Krishna Menon, Felix X. Yu, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025.
  <br>
  [<a href="https://openreview.net/pdf?id=xGs7Ch3Vyo">pdf</a>]
  <br><br>  

  <h3>2024</h3>

  <li> <strong>Regression-aware inference with LLMs</strong>.
  <br>
  Michal Lukasik, Harikrishna Narasimhan, Aditya Krishna Menon, Felix Yu, and Sanjiv Kumar.
  <br>
  In <em>Empirical Methods in Natural Language Processing Findings (<strong>EMNLP Findings</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2403.04182.pdf">pdf</a>]
  <br><br>

  <li> <strong>Unified single-model training achieving diverse scores for information retrieval</strong>.
  <br>
  Seungyeon Kim, Ankit Singh Rawat, Manzil Zaheer, Wittawat Jitkrittum, Veeranjaneyulu Sadhanala, Sadeep Jayasumana, Aditya Krishna Menon, Rob Fergus, and Sanjiv Kumar.
  <br>  
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2024.
  <br>
  [<a href="https://openreview.net/pdf?id=LbEB39lZqp">pdf</a>]
  <br><br>

  <li> <strong>Language model cascades: token-level uncertainty and beyond</strong>.
  <br>
  Neha Gupta, Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>  
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2404.10136">pdf</a>]
  <br><br>
 
  <li> <strong>Learning to reject meets long-tail learning</strong>.
  <br>
  Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, Neha Gupta, and Sanjiv Kumar
  <br>  
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://openreview.net/pdf?id=ta26LtNq2r">pdf</a>]
  <br><br> 

  <li> <strong>Plugin estimators for selective classification with out-of-distribution detection</strong>.
  <br>
  Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, and Sanjiv Kumar.
  <br>  
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2301.12386">pdf</a>]
  <br><br>

  <li> <strong>DistillSpec: improving speculative decoding via knowledge distillation</strong>.
  <br>
  Yongchao Zhou, Kaifeng Lyu, Ankit Singh Rawat, Aditya Krishna Menon, Afshin Rostamizadeh, Sanjiv Kumar, Jean-Fran√ßois Kagy, and Rishabh Agarwal.
  <br>  
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2310.08461">pdf</a>]
  <br><br>

  <li> <strong>Think before you speak: training language models with pause tokens</strong>.
  <br>
  Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, and Vaishnavh Nagarajan.
  <br>  
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2310.02226">pdf</a>]
  <br><br>

  <li> <strong>The importance of feature preprocessing for differentially private linear optimization</strong>.
  <br>
  Ziteng Sun, Ananda Theertha Suresh, and Aditya Krishna Menon.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2307.11106">pdf</a>]
  <br><br>

  <li> <strong>What do larger image classifiers memorise?</strong>
  <br>
  Michal Lukasik, Vaishnavh Nagarajan, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>  
  In <em>Transactions of Machine Learning Research (<strong>TMLR</strong>)</em>, 2024.
  <br>
  [<a href="https://openreview.net/pdf?id=Ew73inSyhG">pdf</a>]
  <br><br>  

  <hr>

  <h3>2023</h3>

  <li> <strong>When does confidence-based cascade deferral suffice?</strong>
  <br>
  Wittawat Jitkrittum, Neha Gupta, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit Singh Rawat, and Sanjiv Kumar.
  <br>  
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023.
  <br>
  [<a href="https://arxiv.org/pdf/2307.02764">pdf</a>]
  <br><br>

  <li> <strong>On student-teacher deviations in distillation: does it pay to disobey?</strong>
  <br>
  Vaishnavh Nagarajan, Aditya Krishna Menon, Srinadh Bhojanapalli, Hossein Mobahi, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023.
  <br>
  [<a href="https://arxiv.org/pdf/2301.12923">pdf</a>]
  <br><br>

  <li> <strong>ResMem: Learn what you can and memorize the rest</strong>.
  <br>
  Zitong Yang, Michal Lukasik, Vaishnavh Nagarajan, Zonglin Li, Ankit Singh Rawat, Manzil Zaheer, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023.
  <br>
  [<a href="https://arxiv.org/pdf/2302.01576">pdf</a>]
  <br><br>  

  <li> <strong>Robust distillation for worst-class performance: on the interplay between teacher and student objectives</strong>.
  <br>
  Serena Wang, Harikrishna Narasimhan, Yichen Zhou, Sara Hooker, Michal Lukasik, and Aditya Krishna Menon.
  <br>
  In <em>Uncertainty in Artificial Intelligence (<strong>UAI</strong>)</em>, 2023.
  <br>
  [<a href="https://proceedings.mlr.press/v216/wang23e/wang23e.pdf">pdf</a>]
  <br><br>

  <li> <strong>Supervision complexity and its role in knowledge distillation</strong>.
  <br>
  Hrayr Harutyunyan, Ankit Singh Rawat, Aditya Krishna Menon, Seungyeon Kim, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2023.
  <br>
  [<a href="https://openreview.net/pdf?id=8jU7wy7N7mA">pdf</a>]
  <br><br>

  <hr>

  <h3>2022</h3>

  <li> <strong>Post-hoc estimators for learning to defer to an expert</strong>.
  <br>
  Harikrishna Narasimhan, Wittawat Jitkrittum, Aditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2022.
  <br>
  [<a href="https://openreview.net/pdf?id=_jg6Sf6tuF7">pdf</a>]
  <br><br>

  <li> <strong>Teacher's pet: understanding and mitigating biases in distillation</strong>.
  <br>
  Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>Transactions of Machine Learning Research (<strong>TMLR</strong>)</em>, 2022.
  <br>
  [<a href="https://openreview.net/pdf?id=ph3AYXpwEb">pdf</a>]
  <br><br>

  <li> <strong>Interval-censored Hawkes processes</strong>.
  <br>
  Marian-Andrei Rizoiu, Alexander Soen, Shidi Li, Pio Calderon, Leanne J. Dong, Aditya Krishna Menon, and Lexing Xie.
  <br>
  In <em>Journal of Machine Learning Research (<strong>JMLR</strong>)</em>, 2022.
  <br>
  [<a href="https://jmlr.org/papers/volume23/21-0917/21-0917.pdf">pdf</a>]
  <br><br>

  <li> <strong>In defense of dual-encoders for neural ranking</strong>.
  <br>
  Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Seungyeon Kim, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2022.
  <br>
  [<a href="https://proceedings.mlr.press/v162/menon22a/menon22a.pdf">pdf</a>]
  <br><br>

  <hr>  

  <h3>2021</h3>

  <li> <strong>Training over-parameterized models with non-decomposable objectives</strong>.
  <br>
  Harikrishna Narasimhan and Aditya Krishna Menon.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2107.04641">pdf</a>]
  <br><br>

  <li> <strong>Disentangling sampling and labeling bias for learning in large-output spaces</strong>.
  <br>
  Ankit Singh Rawat, Aditya Krishna Menon, Wittawat Jitkrittum, Sadeep Jayasumana, Felix X. Yu, Sashank Reddi, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2021.
  <br>
  [<a href="papers/sampling/disentangling.pdf">pdf</a>]
  <br><br>

  <li> <strong>A statistical perspective on distillation</strong>.
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Seungyeon Kim, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2021.
  <br>
  [<a href="papers/distillation/Bayes_Distillation.pdf">pdf</a>]
  <br><br>

  <li> <strong>RankDistil: knowledge distillation for ranking</strong>.
  <br>
  Sashank Reddi, Rama Kumar Pasumarthi, Aditya Krishna Menon, Ankit Singh Rawat, Felix Yu, Seungyeon Kim, Andreas Veit, and Sanjiv Kumar.
  <br>
  In <em>Artificial Intelligence and Statistics (<strong>AISTATS</strong>)</em>, 2021.
  <br>
  [<a href="http://proceedings.mlr.press/v130/reddi21a/reddi21a.pdf">pdf</a>]
  <br><br>

  <li> <strong>Coping with label shift via distributionally robust optimisation</strong>.
  <br>
  Jingzhao Zhang, Aditya Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=BtZhsSGNRNi">pdf</a>]
  <br><br>  

  <li> <strong>Overparameterisation and worst-case generalisation: friend or foe?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=jphnJNOwe36">pdf</a>]
  <br><br>  

  <li> <strong>Long-tail learning via logit adjustment</strong>.
  <br>
  Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021.
  <br>
  [<a href="https://openreview.net/pdf?id=37nvvqkCo5">pdf</a>]
  <br><br>

  <hr>

  <h3>2020</h3>
  <li> <strong>Robust large-margin learning in hyperbolic space</strong>.
  <br>
  Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.05465">pdf</a>]
  <br><br>

  <li> <strong>Semantic label smoothing for sequence to sequence problems</strong>.
  <br>
  Michal Lukasik, Himanshu Jain, Aditya Krishna Menon, Seungyeon Kim, Srinadh Bhojanapalli, Felix Yu and Sanjiv Kumar.
  <br>
  In <em>Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/abs/2010.07447">pdf</a>]
  <br><br>

  <li> <strong>SupMMD: a sentence importance model for extractive summarization using maximum mean discrepancy</strong>.
  <br>
  Umanga Bista, Alexander Patrick Mathews, Aditya Krishna Menon, and Lexing Xie.
  <br>
  In <em>Empirical Methods in Natural Language Processing Findings (<strong>EMNLP Findings</strong>)</em>, 2020.
  <br>
  [<a href="papers/sup-mmd/SupMMD.pdf">pdf</a>]
  <br><br>

  <li> <strong>Does label smoothing mitigate label noise?</strong>
  <br>
  Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2003.02819">pdf</a>]
  <br><br>

  <li> <strong>Supervised learning: no loss no cry</strong>.
  <br>
  Richard Nock and Aditya Krishna Menon.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2002.03555">pdf</a>]
  <br><br>
  
  <li> <strong>Federated learning with only positive labels</strong>.
  <br>
  Felix X. Yu, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.10342">pdf</a>]
  <br><br>

  <li> <strong>Can gradient clipping mitigate label noise?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2020.
  <br>
  [<a href="https://openreview.net/pdf?id=rklB76EKPr">pdf</a>]
  <br><br>

  <hr>

  <h3>2019</h3>

  <li> <strong>Noise-tolerant fair classification</strong>.
  <br>
  Alexandre Louis Lamy, Ziyuan Zhong, Aditya Krishna Menon, and Nakul Verma.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Vancouver, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.10837">pdf</a>]
  <br><br>

  <li> <strong>Multilabel reductions: what is my loss optimising?</strong>
  <br>
  Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Vancouver, 2019.
  <br>
  [<a href="papers/multilabel_reductions/multilabel_reductions.pdf">pdf</a>] [<a href="papers/multilabel_reductions/multilabel_slides.pdf">slides</a>] [<a href="papers/multilabel_reductions/multilabel_poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Fairness risk measures</strong>.
  <br>
  Robert C. Williamson and Aditya Krishna Menon.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.08665">pdf</a>]
  <br><br>

  <li> <strong>Complementary-label learning for arbitrary losses and models</strong>.
  <br>
  Takashi Ishida, Gang Niu, Aditya Krishna Menon, and Masashi Sugiyama.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1810.04327">pdf</a>]
  <br><br>

  <li> <strong>Monge blunts Bayes: hardness results for adversarial training</strong>.
  <br>
  Zac Cranko, Aditya Krishna Menon, Richard Nock, Cheng Soon Ong, Zhan Shi, and Christian Walder.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Long Beach, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1806.02977">pdf</a>]
  <br><br>

  <li> <strong>On the minimal supervision for training any binary classifier from only unlabeled data</strong>.
  <br>
  Nan Lu, Gang Niu, Aditya Krishna Menon and Masashi Sugiyama.
  <br>
  In <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, New Orleans, 2019.
  <br>
  [<a href="https://openreview.net/pdf?id=B1xWcj0qYm">pdf</a>]
  <br><br>

  <li> <strong>Comparative document summarisation via classification</strong>.
  <br>
  Umanga Bista, Alexander Mathews, Minjeong Shin, Aditya Krishna Menon and Lexing Xie.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, Honolulu, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1812.02171v1.pdf">pdf</a>]
  <br><br>

  <li> <strong>The risk of trivial solutions in bipartite top ranking</strong>.
  <br>
  Aditya Krishna Menon.
  <br>
  In <em><strong>Machine Learning</strong></em>, Volume 108, Issue 4, 2019.
  <br>
  [<a href="papers/top-ranking/top-ranking.pdf">pdf</a>]
  <br><br>  

  <hr>

  <h3>2018</h3>

  <li> <strong>A loss framework for calibrated anomaly detection</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, Montreal, 2018.
  <br>
  [<a href="papers/proper-anomaly/proper-anomaly.pdf">pdf</a>]
  <br><br>

  <li> <strong>Learning from binary labels with instance-dependent noise</strong>.
  <br>
  Aditya Krishna Menon, Brendan van Rooyen, and Nagarajan Natarajan.
  <br>    
  In <em><strong>Machine Learning</strong></em>, Volume 107 Issue 8-10 (Special Issue on Papers from <em><strong>ECML-PKDD</strong></em>), 2018.
  <br>
  [<a href="papers/noisetron/noisetron.pdf">pdf</a>]
  <br><br>

  <li> <strong>The cost of fairness in binary classification</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>    
  In <em>Conference on Fairness, Accountability, and Transparency (<strong>FAT</strong>)</em>, New York City, 2018.
  <br>
  [<a href="https://arxiv.org/pdf/1705.09055">pdf</a>]
  <br><br>
  <!-- <br><br> -->  

  <li> <strong>Proper losses for nonlinear Hawkes processes</strong>.
  <br>
  Aditya Krishna Menon and Young Lee.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, New Orleans, 2018.
  <br>
  [<a href="papers/proper_hawkes/proper_hawkes_aaai18.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2017</h3>

  <li> <strong>f-GANs in an information geometric nutshell</strong>.
  <br>
  Richard Nock, Zac Cranko, Aditya Krishna Menon, Lizhen Qu and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NIPS</strong>)</em>, Los Angeles, 2017.
  <br>
  [<a href="papers/vig_gan/vig_gan_nips17.pdf">pdf</a>]
  <br><br>

  <li> <strong>Predicting short-term public transport demand via inhomogeneous Poisson processes</strong>.
  <br>
  Aditya Krishna Menon and Young Lee.
  <br>
  In <em>International Conference on Information and Knowledge Management (<strong>CIKM</strong>)</em>, Singapore, 2017.
  <br>
  [<a href="papers/poisson-regression/poisson_cikm17.pdf">pdf</a>]
  <br><br>

  <li> <strong>Revisiting revisits in trajectory recommendation</strong>.
  <br>
  Aditya Krishna Menon, Dawei Chen, Lexing Xie and Cheng Soon Ong.
  <br>
  In <em>RecSys Workshop on Recommender Systems for Citizens (<strong>CitRec</strong>)</em>, Como, 2017.
  <br>
  [<a href="papers/list_viterbi/list_viterbi.pdf">pdf</a>]
  <br><br>

  <li> <strong>Robust, deep and inductive anomaly detection</strong>.
  <br>
  Raghavendra Chalapathy, Aditya Krishna Menon and Sanjay Chawla.
  <br>
  In <em>European Conference on Machine Learning (<strong>ECML/PKDD</strong>)</em>, Skopje, 2017.
  <br>
  [<a href="papers/robust_ae/robust_ae.pdf">pdf</a>]
  <br><br>

  <li> <strong>Making deep neural networks robust to label noise: a loss correction approach</strong>.
  <br>
  Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, Lizhen Qu.
  <br>
  In <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, Honolulu, 2017.
  <br>
  [<a href="papers/deep-noise/deep-noise-paper.pdf">pdf</a>] [<a href="http://giorgiopatrini.org/assets/slides/2017_CVPR.pdf">slides</a>]
  <br><br>

  <li> <strong>Low-rank linear cold-start recommendation from social data</strong>.
  <br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Lexing Xie, and Darius Braziunas.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, San Francisco, 2017.
  <br>
  [<a href="papers/loco/loco-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>2016</h3>
   
  <li> <strong>Bipartite ranking: a risk-theoretic perspective</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Journal of Machine Learning Research (<strong>JMLR</strong>)</em>, Volume 17, Issue 195. 2016.
  <br>
  [<a href="http://jmlr.org/papers/volume17/14-265/14-265.pdf">pdf</a>] [<a href="javascript:;" onclick="showDiv('liner_bipartite');">liner notes</a>]  

          <div id="liner_bipartite" style="display:none">
            <br>
            <p style='color:gray'>
            Back in 2011, months of exhaustive experimentation with AUC maximisation in the context of link prediction taught me one thing: it's hard to do better than logistic regression. I was excited when later that year, <a href=http://www.icml-2011.org/papers/567_icmlpaper.pdf>Kot≈Çowski et al.</a> gave a compelling theoretical explanation for why this might be.
            <br><br>
            When I joined NICTA in 2013, I followed a rite of passage and read Mark Reid and Bob Williamson's <a href=http://www.jmlr.org/papers/v12/reid11a.html>tour de force</a> on information, divergences, and risks. Tucked away in that paper was a mention of how the AUC related to the concepts presented. I innocently mentioned to Bob that perhaps there was more to be said here. He agreed, and suggested that I start by spelling out what was in my mind.
            <br><br>
            We never expected it would take quite that long to spell.
            [<a href="javascript:;" onclick="hideDiv('liner_bipartite');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <strong>A scaled Bregman theorem with applications</strong>.
  <br>
  Richard Nock, Aditya Krishna Menon and Cheng Soon Ong.
  <br>
  In <em>Advances in Neural Information Processing Systems (<strong>NIPS</strong>)</em>, Barcelona, 2016.
  <br>
  [<a href="https://arxiv.org/abs/1607.00360">pdf</a>]

  <br><br>

  <li> <strong>Linking losses for density ratio and class-probability estimation</strong>.
  <br>
  Aditya Krishna Menon and Cheng Soon Ong.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, New York City, 2016.
  <br>
  [<a href="papers/density-ratio/density-ratio-paper.pdf">pdf</a>] [<a href="papers/density-ratio/density-ratio-slides.pdf">slides</a>] [<a href="papers/density-ratio/density-ratio-poster.pdf">poster</a>] [<a href="papers/density-ratio/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_density');">liner notes</a>]  

          <div id="liner_density" style="display:none">
            <br>
            <p style='color:gray'>
            Long before being introduced to proper losses, I'd known about, and completely accepted, the basic premise as to why density ratio was different to class-probability estimation: the later only <em>indirectly</em> modelled the ratio, which is generally a sub-optimal strategy. Sometime in late 2015, I re-read the cool work on <a href=http://www.jmlr.org/papers/volume10/kanamori09a/kanamori09a.pdf>LSIF</a>. This time, with link functions and partial losses fresh in my mind, I noticed that one could think of this as involving a particular proper loss plus link function. This was mildly interesting, but the point remained: using anything but the link that directly yields the density ratio must be a bad idea.
            <br><br>
            This was something of a defeat for my running theory at the time, that most everything can be attacked with some version of logistic regression. To better understand this failure mode, I was looking at Sugiyama's <a href=http://www.ism.ac.jp/editsec/aism/pdf/10463_2011_Article_343.pdf>elegant unified Bregman view</a> of density ratios. I noticed that logistic regression was mentioned, but didn't pay much attention to it; after all, the Bregman view of regret under proper losses immediately led to the KL minimisation view of logistic regression.
            <br><br>
            It was only on a re-read that I realised there was a bit more to this innocuous result: it was a statement of Bregman minimisation not to the true probability, but to the true density ratio. Now that I didn't know was true for logistic regression. Studying the surprisingly simple proof, I saw it could be viewed as a surprising equality between the KL divergence on probabilities and on ratios.
            <br><br>
            I was sure this couldn't be true in general; but why? I worked through the case of a general divergence, trying to find out the line where the proof would break.
            <br><br>
            Half an hour later, after staring at my working multiple times, I was still incredulous that everything seemed to work in general, too. And so was Lemma 2 born. [<a href="javascript:;" onclick="hideDiv('liner_density');">hide</a>]            
            </p>            
          </div>

  <br><br>

  <li> <strong>Practical linear models for large-scale one-class collaborative filtering</strong>.
  <br>
  Suvash Sedhain, Hung Bui, Jaya Kawale, Nikos Vlassis, Branislav Kveton, Aditya Krishna Menon, Trung Bui and Scott Sanner.
  <br>
  In <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, New York City, 2016.
  <br>
  [<a href="papers/lrec-low/lrec-low-paper.pdf">pdf</a>]

  <br><br>

  <li> <strong>On the effectiveness of linear models for one-class collaborative filtering</strong>.
  <br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Darius Braziunas.
  <br>
  In <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, Phoenix, 2016.
  <br>
  [<a href="papers/lrec/lrec-paper.pdf">pdf</a>] [<a href="papers/lrec/lrec-slides.pdf">slides</a>] [<a href="https://github.com/mesuvash/LRec">code</a>]

  <br><br>

  <hr>

  <h3>2015</h3>

  <li> <strong>Learning with symmetric label noise: the importance of being unhinged</strong>.
  <br>
  Brendan van Rooyen, Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Advances in Neural Processing Systems (<strong>NIPS</strong>)</em>, Montreal, 2015.
  <br>
  [<a href="papers/unhinged/unhinged-paper.pdf">pdf</a>] [<a href="papers/unhinged/unhinged-poster.pdf">poster</a>]

  <br><br>

  <li> <strong>Fine-grained OD estimation with automated zoning and sparsity regularisation</strong>.
  <br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.
  <br>
  In <em><strong>Transportation Research Part B: Methodological</strong></em>, Volume 80, October 2015, Pages 150-172.
  <br>
  [<a href="papers/od-estimation/od-estimation-journal-paper.pdf">pdf</a>]

  <br><br>

  <li> <strong>Learning from corrupted binary labels via class-probability estimation</strong>.
  <br>
  Aditya Krishna Menon, Brendan van Rooyen, Cheng Soon Ong and Robert C. Williamson.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Lille, 2015.
  <br>
  [<a href="papers/corrupted-labels/corrupted-labels-paper.pdf">pdf</a>] [<a href="papers/corrupted-labels/corrupted-labels-slides.pdf">slides</a>] [<a href="papers/corrupted-labels/corrupted-labels-poster.pdf">poster</a>] [<a href="papers/corrupted-labels/index.html">code</a>] [<a href="javascript:;" onclick="showDiv('liner_corrupt');">liner notes</a>]  

          <div id="liner_corrupt" style="display:none">
            <br>
            <p style='color:gray'>
            Ever since I read Elkan and Noto's <a href=https://dl.acm.org/citation.cfm?id=1401920>2008 paper on PU learning</a>, I was fascinated by the topic and their approach; I also felt like I didn't fully grok either, since their sample-selection bias viewpoint was unfamiliar to me. I was inspired to rectify this deficiency on my part when reading one of <a href=http://proceedings.mlr.press/v45/Christoffel15.pdf>du Plessis and Sugiyama's elegant papers</a> that extended this work, and crisply stated the problem in terms of the distributions the underlying samples are drawn from.
            <br><br>
            Around the same time, I also stumbled upon some beautiful works on label noise, notably those of <a href=http://proceedings.mlr.press/v30/Scott13.html>Scott et al.</a> and <a href=https://papers.nips.cc/paper/5073-learning-with-noisy-labels.pdf>Natarajan et al.</a>
            I was struck by the apparent similarity of the two problems, but still couldn't quite decipher the apparently different approaches taken to solve them.
            <br><br>
            At this stage, I sought to clarify in my mind how precisely these different problems relate. Which, as is my wont, involved thinking about them in terms of class-probabilities. On discussing ideas with colleagues at NICTA (serendipitously interested in very similar problems), soon enough we ended up writing this paper. [<a href="javascript:;" onclick="hideDiv('liner_corrupt');">hide</a>]
            </p>
          </div>
  <br><br>

  <li> <strong>AutoRec: autoencoders meet collaborative filtering</strong>.
  <br>
  Suvash Sedhain, Aditya Krishna Menon, Scott Sanner and Lexing Xie.
  <br>
  In <em>International World Wide Web Conference (<strong>WWW</strong>)</em>, Florence, 2015.
  <br>
  [<a href="papers/autorec/autorec-paper.pdf">pdf</a>] [<a href="https://github.com/mesuvash/NNRec">code</a>] [<a href="papers/autorec/autorec-poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Cross-modal retrieval: a pairwise classification approach</strong>.
  <br>
  Aditya Krishna Menon, Didi Surian and Sanjay Chawla.
  <br>
  In <em>SIAM Conference on Data Mining (<strong>SDM</strong>)</em>, Vancouver, 2015.
  <br>
  [<a href="papers/cross-modal/cross-modal-paper.pdf">pdf (with supplementary)</a>] [<a href="papers/cross-modal/cross-modal-slides.pdf">slides</a>] [<a href="papers/cross-modal/index.html">code</a>]
  <br><br>

  <li> <strong>An approach to sparse, fine-grained OD estimation</strong>.
  <br>
  Aditya Krishna Menon, Chen Cai, Weihong Wang, Tao Wen and Fang Chen.
  <br>
  In <em>94th Annual Meeting of the Transporation Research Board (<strong>TRB</strong>)</em>, Washington DC, 2015.
  <br>
  [<a href="papers/od-estimation/od-estimation-paper.pdf">pdf</a>] [<a href="papers/od-estimation/od-estimation-poster.pdf">poster</a>]
  <br><br>

  <hr>

  <h3>2014</h3>

  <li> <strong>Bayes-optimal scorers for bipartite ranking</strong>.
  <br>
  Aditya Krishna Menon and Robert C. Williamson.
  <br>
  In <em>Conference on Learning Theory (<strong>COLT</strong>)</em>, Barcelona, 2014.
  <br>
  [<a href="http://jmlr.org/proceedings/papers/v35/menon14.html">pdf</a>] [<a href="papers/bipartite/bipartite-slides.pdf">slides</a>] [<a href="papers/bipartite/bipartite-poster.pdf">poster</a>]
  <br><br>

  <li> <strong>Inappropriate access detection for electronic health records using collaborative filtering</strong>.
  <br>
  Aditya Krishna Menon, Xiaoqian Jiang, Jihoon Kim, Lucila Ohno-Machado, and Jaideep Vaidya.
  <br>
  In <strong><em>Machine Learning</em></strong>, Volume 95 Number 1, Special Issue on Machine Learning for Society</em></strong>, 2014.
  <br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5376-1">pdf</a>]
  <br><br>

  <hr>

  <h3>2013</h3>

  <li> <strong>A colorful approach to text processing by example</strong>.
  <br>
  Kuat Yessenov, Shubham Tulsiani, Aditya Krishna Menon, Robert C. Miller, Sumit Gulwani, Butler Lampson, and Adam Kalai.
  <br>In <em>ACM Symposium on User Interface Software and Technology (<strong>UIST</strong>)</em>, 2013.
  <br>
  [<a href="http://dl.acm.org/citation.cfm?id=2502040">pdf</a>]
  <br><br>

  <li> <strong>Beam search algorithms for multilabel learning</strong>.
  <br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.
  <br>
  In <strong><em>Machine Learning</em></strong>, 2013.
  <br>
  [<a href="http://link.springer.com/article/10.1007%2Fs10994-013-5371-6">pdf</a>]
  <br><br>

  <li> <strong>On the statistical consistency of algorithms for binary classification under class imbalance</strong>.
  <br>
  Aditya Krishna Menon, Harikrishna Narasimhan, Shivani Agarwal and Sanjay Chawla.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Atlanta, 2013.
  <br>
  [<a href="http://jmlr.org/proceedings/papers/v28/menon13a.pdf">pdf</a>] [<a href="papers/imbalance/imbalance-slides.pdf">slides</a>]
  <br><br>

  <li> <strong>A machine learning framework for programming by example</strong>.
  <br>
  Aditya Krishna Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, and Adam Tauman Kalai.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Atlanta, 2013.
  <br>
  [<a href="http://jmlr.csail.mit.edu/proceedings/papers/v28/menon13.pdf">pdf</a>] [<a href="papers/pbe/pbe-poster.pdf">poster</a>] [<a href="papers/pbe/index.html">data</a>]
  <br><br>

  <hr>

  <h3>2012</h3>

  <li> <strong>Learning and inference in Probabilistic Classifier Chains with beam search</strong>.
  <br>
  Abhishek Kumar, Shankar Vembu, Aditya Krishna Menon, and Charles Elkan.
  <br>
  In <em>Machine Learning and Knowledge Discovery in Databases - European Conference (<strong>ECML-PKDD</strong>), Proceedings Part I</em>, 2012.
  <br>
  [<a href="http://www.springerlink.com/content/m71407113726156x/">pdf</a>]
  <br><br>

  <li> <strong>Doubly optimized calibrated Support Vector Machine (DOC-SVM): an algorithm for joint optimization of discrimination and calibration</strong>.
  <br>
  Xiaoqian Jiang, Aditya Krishna Menon, Shuang Wang, Jihoon Kim, and Lucila Ohno-Machado.
  <br>
  In <strong><em>PLoS ONE</strong></em>, 7(11): e48823, 2012.
  <br>
  [<a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048823">pdf</a>] 
  <br><br>

  <li> <strong>Predicting accurate probabilities with a ranking loss</strong>.
  <br>
  Aditya Krishna Menon, Xiaoqian Jiang, Shankar Vembu, Charles Elkan, and Lucila Ohno-Machado.
  <br>
  In <em>International Conference on Machine Learning (<strong>ICML</strong>)</em>, Edinburgh, 2012.
  <br>
  [<a href="http://icml.cc/2012/papers/372.pdf">pdf</a>] [<a href="papers/calibration/calibration-poster.pdf">poster</a>] [<a href="papers/calibration/index.html">code</a>]
  <br><br>

  <hr>

  <h3>2011</h3>

  <li> <strong>Link prediction via matrix factorization</strong>.
  <br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>Machine Learning and Knowledge Discovery In Databases - European Conference,
  <strong>ECML-PKDD</strong>, Proceedings Part II</em>, 2011.
  <br>
  [<a href="https://link.springer.com/chapter/10.1007/978-3-642-23783-6_28">pdf</a>] [<a href="papers/link-prediction/link-prediction-poster.pdf">poster</a>] [<a href="papers/link-prediction/index.html">code</a>]
  <br><br>

  <li> <strong>Response prediction using collaborative filtering with hierarchies and side-information</strong>.
  <br>
  Aditya Krishna Menon, Krishna-Prasad Chitrapura, Sachin Garg, Deepak Agarwal, and Nagaraj Kota.
  <br>
  In <em>Knowledge Discovery and Data Mining (<strong>KDD</strong>)</em>, San Diego, 2011.
  <br>
  [<a href="papers/response-prediction/response-prediction-paper.pdf">pdf</a>] [<a href="papers/response-prediction/response-prediction-slides.pdf">slides</a>] [<a href="papers/response-prediction/response-prediction-poster.pdf">poster</a>] [<a href="papers/response-prediction/code.zip">code</a>]
  <br><br>

  <hr>

  <h3>2010</h3>

  <li> <strong>Fast algorithms for approximating the singular value decomposition</strong>.
  <br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>Transactions of Knowledge and Data Discovery: Special Issue on Large-Scale Data Mining (<strong>TKDD-LDMTA</strong>)</em>, 2010.
  <br>
  [<a href="http://dl.acm.org/citation.cfm?id=1921639">pdf</a>] [<a href="papers/code-fastsvd.zip">code</a>]
  <br><br>

  <li> <strong>A log-linear model with latent features for dyadic prediction</strong>.
  <br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em>International Conference on Data Mining (<strong>ICDM</strong>)</em>, Sydney, 2010.
  <br>
  [<a href="papers/lfl/lfl-paper.pdf">pdf</a>] [<a href="papers/lfl/lfl-slides.pdf">slides</a>] [<a href="papers/lfl/index.html">code</a>]
  <br><br>

  <li> <strong>Predicting labels for dyadic data</strong>.
  <br>
  Aditya Krishna Menon, Charles Elkan.
  <br>
  In <em><strong>Data Mining and Knowledge Discovery</strong></em>, Special Issue on Papers from <strong><em>ECML-PKDD</em></strong></em> Volume 21, Number 2, 2010.
  <br>
  [<a href="http://www.springerlink.com/content/115p058437104h7k/fulltext.pdf">pdf</a>] [<a href="papers/labels-dyadic/labels-dyadic-slides.pdf">slides</a>]
  <br><br>

  <hr>

  <h3>2007</h3>

  <li> <strong>An incremental data-stream sketch using sparse random projections</strong>.
  <br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.
  <br>
  In <em>SIAM Conference on Data Mining (<strong>SDM</strong>)</em>, Minnesota, 2007.
  <br>
  [<a href="papers/random-projections/random-projections-paper.pdf">pdf</a>]
  <br><br>

  <hr>

  <h3>Manuscripts</h3>

  <li> <strong>Cascade-aware training of language models</strong>.
  <br>
  Congchao Wang, Sean Augenstein, Keith Rush, Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Aditya Krishna Menon, and Alec Go.
  <br>
  Manuscript, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2406.00060">pdf</a>]
  <br><br>

  <li> <strong>Efficient document ranking with learnable late interactions</strong>.
  <br>
  Ziwei Ji, Himanshu Jain, Andreas Veit, Sashank J. Reddi, Sadeep Jayasumana, Ankit Singh Rawat, Aditya Krishna Menon, Felix Yu, and Sanjiv Kumar.
  <br>
  Manuscript, 2024.
  <br>
  [<a href="https://arxiv.org/pdf/2406.17968.pdf">pdf</a>]
  <br><br>

  <li> <strong>EmbedDistill: a geometric knowledge distillation for information retrieval</strong>.
  <br>
  Seungyeon Kim, Ankit Singh Rawat, Manzil Zaheer, Sadeep Jayasumana, Veeranjaneyulu Sadhanala, Wittawat Jitkrittum, Aditya Krishna Menon, Rob Fergus, and Sanjiv Kumar.
  <br>
  Manuscript, 2023.
  <br>
  [<a href="https://arxiv.org/pdf/2301.12005">pdf</a>]
  <br><br>

  <li> <strong>When in doubt, summon the titans: efficient inference with large models</strong>.
  <br>
  Ankit Singh Rawat, Manzil Zaheer, Aditya Krishna Menon, Amr Ahmed, and Sanjiv Kumar.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2110.10305">pdf</a>]
  <br><br>

  <li> <strong>ELM: embedding and logit margins for long-tail learning</strong>.
  <br>
  Wittawat Jitkrittum, Aditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar.
  <br>
  Manuscript, 2022.
  <br>
  [<a href="https://arxiv.org/pdf/2204.13208.pdf">pdf</a>]
  <br><br>

  <li> <strong>Distilling double descent</strong>.
  <br>
  Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit Singh Rawat, Sashank J. Reddi, and Yichen Zhou.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2102.06849">pdf</a>]
  <br><br>  

  <li> <strong>On the reproducibility of neural network predictions</strong>.
  <br>
  Srinadh Bhojanapalli, Kimberly Wilber, Andreas Veit, Ankit Singh Rawat, Seungyeon Kim, Aditya Krishna Menon, and Sanjiv Kumar.
  <br>
  Manuscript, 2021.
  <br>
  [<a href="https://arxiv.org/pdf/2102.03349">pdf</a>]
  <br><br>

  <li> <strong>Doubly-stochastic mining for heterogeneous retrieval</strong>.
  <br>
  Ankit Singh Rawat, Aditya Krishna Menon, Andreas Veit, Felix Yu, Sashank J. Reddi, and Sanjiv Kumar.
  <br>
  Manuscript, 2020.
  <br>
  [<a href="https://arxiv.org/pdf/2004.10915">pdf</a>]
  <br><br>

  <li> <strong>Cold-start playlist recommendation with multitask learning</strong>.
  <br>
  Dawei Chen, Cheng Soon Ong, and Aditya Krishna Menon.
  <br>
  Manuscript, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1901.06125">pdf</a>]
  <br><br>

  <li> <strong>Structured recommendation</strong>.
  <br>
  Dawei Chen, Lexing Xie, Aditya Krishna Menon, and Cheng Soon Ong.
  <br>
  Manuscript, 2019.
  <br>
  [<a href="https://arxiv.org/pdf/1706.09067">pdf</a>]
  <br><br>

  <li> <strong>Large-scale Support Vector Machines: algorithms and theory</strong>.
  <br>
  Aditya Krishna Menon.
  <br>
  Research Exam, University of California, San Diego. 2009.
  <br>
  [<a
  href="papers/research-exam/research-exam-paper.pdf">pdf</a>] [<a href="papers/research-exam/research-exam-slides.pdf">slides</a>]
  <br><br>

  <li> <strong>An incremental data-stream sketch using sparse random projections</strong>.
  <br>
  Aditya Krishna Menon, Gia Vinh Anh Pham, Sanjay Chawla and Anastasios Viglas.
  <br>
  Technical Report 609, University of Sydney. 2007.
  <br>
  [<a href="papers/random-projections/random-projections-tr-paper.pdf">pdf</a>]
  <br><br>  

  <li> <strong>Random projections and applications to dimensionality reduction</strong>.
  <br>
  Aditya Krishna Menon.
  <br>
  Honours thesis, University of Sydney. 2006.
  <br>
  [<a href="papers/honours/honours-thesis.pdf">pdf</a>] [<a href="papers/honours/honours-slides.pdf">slides</a>]  

  </ul>

  <hr>

  </div>

</div>

</body>

</html>
